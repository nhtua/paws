# Python Executor Architecture for PAWS and ACI Workflow

Think of the Executor not as an "AI," but as a **Virtual Machine** (like a Java VM or Game Engine) that reads a script (AOL) and strictly executes it step-by-step.

> [!NOTE]
> AOL v1.0 uses YAML format for deterministic parsing. The Executor uses standard YAML parsers (e.g., PyYAML) and Pydantic models for validation.

### 1. Module: aol_parser.py (The Loader)

This module acts as the "front-end" of your compiler. It reads the YAML file and converts it into a structured object the machine can understand. It does not execute code; it validates the schema.

* **load_aol_file(file_path: str) -> WorkflowPlan**  
  * Reads the raw .aol YAML file.  
  * Parses the three mandatory sections: Provider, User Inputs, and Workflow Logic.  
  * Validates against Pydantic schema (AOLWorkflow model).
  * Returns a structured WorkflowPlan object (a list of steps).  
* **validate_dependencies(plan: WorkflowPlan) -> bool**  
  * Checks Section 1 (Provider Description) to ensure all required tools (e.g., "ffmpeg", "ComfyUI") and credentials exist in the system before starting.

### 2. Module: state_manager.py (The Memory)

This handles **Event Sourcing**. The Executor is stateless; this module ensures that if the system crashes, it can reload the log and resume exactly where it left off.

* **initialize_state(user_inputs: dict) -> EventLog**  
  * Creates a new append-only log.  
  * Records "State Zero" using the inputs from AOL Section 2.  
* **append_event(event_type: str, payload: dict) -> None**  
  * Writes an action or observation to the permanent log (e.g., JSON file or database).  
  * *Example:* append_event("ACTION_START", {"step": 1, "tool": "ffmpeg"}).  
* **get_last_successful_step() -> int**  
  * Reads the log to find the last step that emitted a "SUCCESS" event, allowing the Executor to skip already-completed steps upon a restart.

### 3. Module: mcp_client.py (The Translation Layer)

This is the **Agent-Computer Interface (ACI)**. This module isolates the Executor from the messy details of CLI commands. It treats tools as "Black Boxes" via the **Model Context Protocol (MCP)**.

* **discover_tools() -> dict**  
  * Scans for available MCP servers (Extensions) and loads their capability schemas (e.g., knowing that the "ffmpeg" tool has a function called combine_videos).  
* **send_payload(tool_name: str, function_name: str, arguments: dict) -> ExecutionResult**  
  * **The "Clean" Input:** Takes a high-level command (e.g., {"action": "convert", "file": "video.mp4"}).  
  * **The Handoff:** Sends this JSON to the specific Tool's Python wrapper. The wrapper (external to this module) handles the binary translation (e.g., generating the ffmpeg \-i ... command).  
* **parse_observation(raw_output: str) -> dict**  
  * Receives the raw standard output/error (stdout/stderr) from the tool.  
  * Standardizes it into a clean JSON observation for the Event Log.

### 4. Module: security.py (The Jailer)

This enforces **Safety via Isolation**. It ensures the plan typically generated by an AI doesn't destroy the host machine.

* **verify_entitlements(tool_name: str, target_path: str) -> bool**  
  * Checks if the tool is allowed to touch the requested file.  
  * *Rule:* Tools should only have read/write access to specific asset folders (e.g., ./workspace/assets/), blocking access to root system files.  
* **enforce_resource_limits(container_id: str) -> None**  
  * (Optional) If running tools in Docker, this ensures a tool doesn't consume 100% CPU or RAM, preventing "Shared Fate" failures.

### 5. Module: validator.py (The Critic)

This implements the **Evaluator-Optimizer** pattern. It checks if a step actually succeeded, rather than just assuming it did because the code didn't crash.

* **validate_step(step_output: dict, success_criteria: dict) -> bool**  
  * Performs "Semantic Checks."  
  * *Example:* If the step was "Generate Image," this function checks: "Does the output file exist?" AND "Is the file size \> 0 bytes?"  
* **trigger_feedback_loop(error_log: dict) -> NewPlan**  
  * If validation fails, this prepares the data to send back to the Planner (LLM) to request a corrected AOL file.

### 6. Module: executor_engine.py (The Main Loop)

This ties everything together using the **OODA Loop** (Observe-Orient-Decide-Act).

* **run_workflow(aol_file: str)**  
  * **Step 1:** Call aol_parser.load_aol_file() to parse YAML and validate schema.  
  * **Step 2:** Call state_manager.initialize_state().  
  * **Step 3 (The Loop):** Iterate through the steps in the Plan.  
    * **Observe:** state_manager.get_last_successful_step().  
    * **Orient:** Determine the next pending step from the Plan.  
    * **Decide:** security.verify_entitlements().  
    * **Act:** mcp_client.send_payload() -> Wait for parse_observation().  
    * **Verify:** validator.validate_step().  
    * **Log:** state_manager.append_event().

---

*See [AOL v1.0 Specification.md](./AOL%20v1.0%20Specification.md) for the complete language reference.*
